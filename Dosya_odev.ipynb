{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duzensiz ve duplicate veriden oluşan \"all_data.txt\" dosyası üzerinde yapılan işlemler.**\n",
    "\n",
    "\n",
    "    * Bütün text küçük harfe çevrilecek\n",
    "    * Türkçe karakterler replace edilecek\n",
    "        ş -> s\n",
    "        ı -> i\n",
    "        ö -> o\n",
    "        ğ -> g\n",
    "        ç -> c\n",
    "        ü -> u\n",
    "    * Bir satır tamamen sayılardan oluşuyorsa satırı yeni dosyaya eklememelisin\n",
    "    * Her satırda bir cümle olacak şekilde satırları düzenleyin. yani bir cümlenin bitişi ve yeni cümlenin başlangıcı aynı satırda olmayacak.\n",
    "\n",
    "    * Noktalama işaretleri kaldırılacak #regex \n",
    "    * duplicate veri barındırmayacak- kelime bazında degil satır bazında\n",
    "\n",
    "    her bir olay için for loop yapmana gerek yok\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-Duplicate satırların kaldırılması:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "with open(\"all_data.txt\", 'r') as text, open(\"new_all_data1.txt\", \"w\") as new_text1:\n",
    "    completed_lines_hash = set()\n",
    "\n",
    "\n",
    "    for line in text:\n",
    "\t\n",
    "\t    hashValue = hashlib.md5(line.rstrip().encode('utf-8')).hexdigest()\n",
    "\t\n",
    "\t    if hashValue not in completed_lines_hash:\n",
    "\t\t    new_text1.write(line)\n",
    "\t\t    completed_lines_hash.add(hashValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Aynı line'da biten cümleden sonra gelen yeni cümleyi yeni line'a yazdırma:**\n",
    "\n",
    "Burada kullandığım kod, biten bir cümlenin ardından yeni başlayan cümleleri yeni satıra yazdırabilmemim yanı sıra\n",
    "sayılardan sonra gelen kelimeleri de yeni satıra yazdırıyor.\n",
    "\n",
    "Bunu önlemek için nltk.tokenzie ile aşağıdaki farklı bir kod yazdım. Fakat bilgisayarıma nltk yi kuramadığım için yazdıramadım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "\n",
    "#from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#with open(\"new_all_data1.txt\", 'r') as text, open(\"new_all_data2.txt\", \"w\") as new_text2:\n",
    "#    for line in text:\n",
    "#        line = sent_tokenize(text)\n",
    "#        new_text2.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(\"new_all_data1.txt\", 'r') as text, open(\"new_all_data2.txt\", \"w\") as new_text2:\n",
    "    text_lines = text.readlines()\n",
    "\n",
    "    for line in text_lines:\n",
    "\n",
    "        if \".\" in line:\n",
    "\n",
    "            new_lines = re.sub(r\"(?<=\\.) (?=[A-Z])\", \"\\n\", line )\n",
    "            new_text2.write(new_lines)\n",
    "\n",
    "        else:\n",
    "            new_text2.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 & 4-Küçük harflere çevrilmesi & Türkçe karakterlerin değiştirilmesi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"new_all_data2.txt\", 'r+') as text, open(\"new_all_data3.txt\", \"w\") as new_text3:\n",
    "      text_data = text.readlines()\n",
    "      for line in text_data:  \n",
    "         line = line.lower()\n",
    "         line = line.replace('ş', 's')\n",
    "         line = line.replace('ı', 'i')\n",
    "         line = line.replace('ö', 'o')\n",
    "         line = line.replace('ğ', 'g')\n",
    "         line = line.replace('ç', 'c')\n",
    "         line = line.replace('ü', 'u')\n",
    "         new_text3.write(line)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5- Sadece numaralardan oluşan satırların silinmesi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_all_data3.txt\", 'r') as text, open(\"new_all_data4.txt\", \"w\") as new_text4:\n",
    "    for line in text:\n",
    "        newline = line.rstrip('\\r\\n')\n",
    "        if not (newline.replace(\" \", \"\").isdigit()):\n",
    "            new_text4.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6- Noktalama işaretlerinin kaldırılması:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maketrans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [94], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_all_data4.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m text, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_all_data5.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m new_text5:\n\u001b[0;32m----> 2\u001b[0m     allPunct \u001b[38;5;241m=\u001b[39m \u001b[43mmaketrans\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!#$\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m&\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m()*+,-/:;.<=>?@[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]^_`\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m|}~\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \n\u001b[1;32m      3\u001b[0m     newtext \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mtranslate(allPunct) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m text]\n\u001b[1;32m      4\u001b[0m     new_text5\u001b[38;5;241m.\u001b[39mwrite(newtext)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'maketrans' is not defined"
     ]
    }
   ],
   "source": [
    "#with open(\"new_all_data4.txt\", 'r') as text, open(\"new_all_data5.txt\", \"w\") as new_text5:\n",
    "#    allPunct = maketrans('', '', (\"!#$%&'()*+,-/:;.<=>?@[\\]^_`{|}~\")) \n",
    "#    newtext = [line.translate(allPunct) for line in text]\n",
    "#    new_text5.write(newtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All_punct = \"!#$%&'()*+,-/:;.<=>?@[\\]^_`•©{|}~\"\n",
    "\n",
    "with open(\"new_all_data4.txt\", 'r') as text, open(\"new_all_data5.txt\", \"w\") as new_text5:\n",
    "    text_data = text.readlines()\n",
    "    for line in text_data:\n",
    "        line = line.replace(\"-\", \"\")\n",
    "        line = line.replace(\"!\", \"\")\n",
    "        line = line.replace(\"&\", \"\")\n",
    "        line = line.replace(\"#\", \"\")\n",
    "        line = line.replace(\"%\", \"\")\n",
    "        line = line.replace(\".\", \"\")\n",
    "        line = line.replace(\"$\", \"\")\n",
    "        line = line.replace(\"(\", \"\")\n",
    "        line = line.replace(\")\", \"\")\n",
    "        line = line.replace(\"*\", \"\")\n",
    "        line = line.replace(\"+\", \"\")\n",
    "        line = line.replace(\",\", \"\")\n",
    "        line = line.replace(\"-\", \"\")\n",
    "        line = line.replace(\"/\", \"\")\n",
    "        line = line.replace(\"<\", \"\")\n",
    "        line = line.replace(\">\", \"\")\n",
    "        line = line.replace(\"=\", \"\")\n",
    "        line = line.replace(\"?\", \"\")\n",
    "        line = line.replace(\"@\", \"\")\n",
    "        line = line.replace(\"[\", \"\")\n",
    "        line = line.replace(\"]\", \"\")\n",
    "        line = line.replace(\"©\", \"\")\n",
    "        line = line.replace(\"»\", \"\")\n",
    "        line = line.replace(\"'\", \"\")\n",
    "        line = line.replace(\"•\", \"\")\n",
    "        line = line.replace(\":\", \"\")\n",
    "        line = line.replace(\"“\", \"\")\n",
    "        line = line.replace(\"”\", \"\")\n",
    "        line = line.replace(\"–\", \"\")\n",
    "\n",
    "\n",
    "        new_text5.write(line)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex ile noktalama işaretlerini kaldırma:**\n",
    "Aşağıdaki kodu denedim ama yazdıramadım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "\n",
    "#with open(\"new_all_data4.txt\", 'r') as text, open(\"new_all_data5.txt\", \"w\") as new_text5:\n",
    "# text_data = text.readlines()\n",
    "#    for line in text: \n",
    "#        newline = line.rstrip('\\r\\n')\n",
    "#        new_text5 = re.sub(r'[^\\w\\s]', '', line)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
